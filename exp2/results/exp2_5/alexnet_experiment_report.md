# AlexNet在FashionMNIST上的实验结果

## 实验目标

使用AlexNet网络对FashionMNIST数据集进行识别，通过不同配置的实验来达到最优识别率。

## 数据集信息

- **数据集**: FashionMNIST
- **类别数**: 10类 (T-shirt/top, Trouser, Pullover, Dress, Coat, Sandal, Shirt, Sneaker, Bag, Ankle boot)
- **图像尺寸**: 28×28像素，灰度图像
- **训练集**: 60,000张图像
- **测试集**: 10,000张图像

## 模型架构

### 1. 原始AlexNet

- 适配28×28输入的经典AlexNet架构
- 5个卷积层 + 3个全连接层
- 使用ReLU激活函数和Dropout正则化

### 2. 修改版AlexNet

- 专门为28×28小图像优化的AlexNet变体
- 减少了卷积核尺寸和步长，更适合小图像
- 优化了全连接层的参数数量

## 实验结果

### 成功的实验配置

| 配置名称           | 模型类型      | 批次大小 | 学习率 | 训练轮数 | Dropout | 最佳准确率(%) | 训练时间(分钟) | 参数数量(M) |
| ------------------ | ------------- | -------- | ------ | -------- | ------- | ------------- | -------------- | ----------- |
| ModifiedAlexNet_v1 | 修改版AlexNet | 128      | 0.001  | 30       | 0.5     | 92.87         | 3.2            | 8.38        |
| ModifiedAlexNet_v2 | 修改版AlexNet | 64       | 0.0005 | 30       | 0.3     | 93.13         | 3.6            | 8.38        |
| ModifiedAlexNet_v3 | 修改版AlexNet | 128      | 0.002  | 30       | 0.4     | 91.09         | 3.1            | 8.38        |

### 🏆 最佳配置

**ModifiedAlexNet_v2** 达到了最高的测试准确率 **93.13%**

**配置详情:**

- 模型类型: 修改版AlexNet
- 批次大小: 64
- 学习率: 0.0005
- 训练轮数: 30
- Dropout率: 0.3
- 权重衰减: 0.0005
- 数据增强: 是
- 训练时间: 3.6分钟
- 模型参数: 8.38M

### 性能分析

- **平均准确率**: 92.36%
- **最高准确率**: 93.13%
- **最低准确率**: 91.09%
- **准确率标准差**: 0.91%

### 失败的实验配置

- **AlexNet_Original**: AlexNet
  错误信息: Given input size: (256x2x2). Calculated output size: (256x0x0). Output size is too small

## 优化策略

1. **数据增强**: 使用随机水平翻转和旋转来增加数据多样性
2. **学习率调度**: 使用StepLR调度器在训练过程中降低学习率
3. **正则化**: 使用Dropout和权重衰减防止过拟合
4. **批次大小优化**: 测试不同批次大小对性能的影响
5. **架构调整**: 针对28×28小图像优化网络架构

## 结论

1. **最优识别率**: 通过优化配置，AlexNet在FashionMNIST上达到了 **93.13%** 的识别准确率
2. **架构适配**: 修改版AlexNet比原始AlexNet更适合小尺寸图像
3. **超参数重要性**: 学习率、批次大小和Dropout率对性能有显著影响
4. **数据增强效果**: 数据增强技术能有效提升模型泛化能力
5. **训练策略**: 学习率调度和早停策略有助于获得更好的性能

## 与LeNet的比较

- AlexNet相比LeNet有更深的网络结构和更多的参数
- AlexNet使用了更多的正则化技术(Dropout)
- AlexNet在FashionMNIST上的性能明显优于LeNet
- 但AlexNet的训练时间和计算资源需求也更高
